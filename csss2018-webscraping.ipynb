{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datascraping : Web Scraping / APIs\n",
    "Dec 10th, 2018 - Javier Garcia-Bernardo, Anna Keuchenius & Allie Morgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requirements\n",
    "import requests               # Simple HTTP operations (GET and POST)\n",
    "import selenium               # Loads dynamic (javascript) pages\n",
    "import json                   # Parsing the responses from APIs\n",
    "import re                     # Python library for parsing regular expressions\n",
    "from bs4 import BeautifulSoup # Parsing HTML\n",
    "import pandas as pd           # Read tables\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is datascraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data scraping](https://en.wikipedia.org/wiki/Web_scraping) is a method for extracting data from the web. There are many techniques which can be used for web scraping‚Ää‚Äî‚Ääranging from requiring human involvement (‚Äúhuman copy-paste‚Äù) to fully automated systems (using computer vision). Somewhere in the middle is HTML parsing, which we will describe here.\n",
    "\n",
    "Web scraping using [HTML parsing](https://en.wikipedia.org/wiki/Web_scraping#HTML_parsing) is often used on webpages which share similar HTML structure. For example, you might want to scrape the ingredients from chocolate chip cookie recipes to identify correlations between ingredients and five-star worthy cookies, or you might want to predict who will win March Madness by looking at game play-by-plays, or you want to know all the local pets up for adoption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Static Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of basics request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://cssamsterdam.github.io/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<!DOCTYPE html>\\r\\n<!--[if IE 8 ]><html class=\"no-js oldie ie8\" lang=\"en\"> <![endif]-->\\r\\n<!--[if IE 9 ]><html class=\"no-js oldie ie9\" lang=\"en\"> <![endif]-->\\r\\n<!--[if (gte IE 9)|!(IE)]><!--><html class=\"no-js\" lang=\"en\"> <!--<![endif]-->\\r\\n<head>\\r\\n\\r\\n   <!--- basic page needs\\r\\n   ================================================== -->\\r\\n   <meta charset=\"utf-8\">\\r\\n\\t<title>Computational Social Science -- Amsterdam</title>\\r\\n\\t<meta name=\"description\" content=\"\">  \\r\\n\\t<meta name=\"author\" content=\"\">\\r\\n\\r\\n   <!-- mobile specific metas\\r\\n   ================================================== -->\\r\\n\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\">\\r\\n\\r\\n \\t<!-- CSS\\r\\n   ================================================== -->\\r\\n   <link rel=\"stylesheet\" href=\"css/base.css\">  \\r\\n   <link rel=\"stylesheet\" href=\"css/main.css\">\\r\\n   <link rel=\"stylesheet\" href=\"css/vendor.css\">  \\r\\n\\r\\n\\r\\n   <!-- script\\r\\n   ================================================== -->\\r\\n\\t<script src=\"js/moderni'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<head>\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta charset=\"utf-8\" />\n",
      "<link rel=\"shortcut icon\" href=\"https://www.boulderhumane.org/sites/default/files/favicon.ico\" type=\"image/vnd.microsoft.icon\" />\n",
      "<meta name=\"Generator\" content=\"Drupal 7 (http://drupal.org)\" />\n",
      "<meta name=\"viewport\" content=\"width=1000px, initial-scale=1.0, maximum-scale=1.0\" />\n",
      "<title>Dogs Available for Adoption | Humane Society of Boulder Valley</title>\n",
      "<link type=\"text/css\" rel=\"stylesheet\n"
     ]
    }
   ],
   "source": [
    "urls = [\"https://www.boulderhumane.org/animals/adoption/dogs\", \n",
    "         \"https://www.boulderhumane.org/animals/adoption/cats\", \n",
    "         \"https://www.boulderhumane.org/animals/adoption/adopt_other\"]\n",
    "\n",
    "page = requests.get(urls[0])\n",
    "# Extractt \n",
    "html = page.text\n",
    "print(html[:500]) # Print the first 500 characters of the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information: parsing html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you visit a webpage, your web browser renders an HTML document with CSS and Javascript to produce a visually appealing page. (See the HTML above.) [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) is a Python library for parsing HTML. We'll use it to extract all of the names, ages, and breeds of the [dogs](https://www.boulderhumane.org/animals/adoption/dogs), [cats](https://www.boulderhumane.org/animals/adoption/cats), and [small animals](https://www.boulderhumane.org/animals/adoption/adopt_other) currently up for adoption at the Boulder Humane Society."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that the feature of these pages which we are exploiting is their repeated HTML structure. Every animal listed has the following HTML variant:\n",
    "```{html}\n",
    "<div class=\"views-row ... \">\n",
    "  ...\n",
    "  <div class=\"views-field views-field-field-pp-animalname\">\n",
    "    <div class=\"field-content\">\n",
    "      <a href=\"/animals/adoption/\" title=\"Adopt Me!\">Romeo</a>\n",
    "    </div>\n",
    "  </div>\n",
    "  <div class=\"views-field views-field-field-pp-primarybreed\">\n",
    "    <div class=\"field-content\">New Zealand</div>\n",
    "  </div>\n",
    "  <div class=\"views-field views-field-field-pp-secondarybreed\">\n",
    "    <div class=\"field-content\">Rabbit</div>\n",
    "  </div>\n",
    "  <div class=\"views-field views-field-field-pp-age\">\n",
    "    ...\n",
    "    <span class=\"field-content\">0 years 2 months</span>\n",
    "  </div>\n",
    "  <div class=\"views-field views-field-field-pp-gender\">\n",
    "    ...\n",
    "    <span class=\"field-content\">Male</span>\n",
    "  </div>\n",
    "  ...\n",
    "</div>\n",
    "``` \n",
    "So to get at the HTML object for each pet, we can run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = soup.find_all('div', {'class': re.compile('.*views-row.*')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, find all of the `div` tags with the `class` attribute which contains the substring `views-row`. \n",
    "\n",
    "remark: notice that we use regex here in the re.compile statement. Regex helps to find patterns in text. More info on regex [here](https://docs.python.org/3/library/re.html). The wildcard .* matches everything (all characters).\n",
    "\n",
    "Next, to grab the name, breeds, and ages of these pets, we‚Äôll grab the children of each pet HTML object. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Blue', u'Coonhound, Treeing Walker', u'', u'Age:7 years 5 months')\n",
      "(u'Calvin', u'Pointer, German Shorthaired', u'Mix', u'Age:1 year 9 months')\n",
      "(u'Mona', u'Greyhound', u'Retriever, Labrador', u'Age:8 years 1 month')\n",
      "(u'Iris', u'Siberian Husky', u'Saint Bernard', u'Age:7 years 0 months')\n",
      "(u'Lucia', u'Chihuahua, Short Coat', u'Mix', u'Age:6 years 0 months')\n",
      "(u'Karma', u'Terrier, American Pit Bull', u'Mix', u'Age:3 years 0 months')\n",
      "(u'Chuco', u'Terrier, American Pit Bull', u'Mix', u'Age:3 years 7 months')\n",
      "(u'Harper', u'Terrier, American Pit Bull', u'Mix', u'Age:1 year 1 month')\n",
      "(u'Lupita', u'Bulldog, American', u'Mix', u'Age:2 years 0 months')\n",
      "(u'Winston', u'Chihuahua, Short Coat', u'Mix', u'Age:1 year 0 months')\n",
      "(u'Beans', u'Terrier, American Pit Bull', u'Mix', u'Age:0 years 2 months')\n",
      "(u'Coco', u'Bulldog, English', u'Mix', u'Age:0 years 5 months')\n",
      "(u'Oliver', u'Alaskan Klee Kai', u'', u'Age:7 years 10 months')\n",
      "(u'Canon', u'Siberian Husky', u'Mix', u'Age:3 years 0 months')\n",
      "(u'Eve', u'Miniature Pinscher', u'', u'Age:0 years 4 months')\n",
      "(u'Buck', u'Retriever, Labrador', u'Mix', u'Age:1 year 2 months')\n",
      "(u'Idgie', u'Siberian Husky', u'Mix', u'Age:0 years 3 months')\n",
      "(u'Ruth', u'Siberian Husky', u'Mix', u'Age:0 years 3 months')\n"
     ]
    }
   ],
   "source": [
    "head = \"views-field views-field-field-pp-\"\n",
    "for pet in pets:\n",
    "    name = pet.find('div', {'class': head + 'animalname'}).get_text(strip=True)\n",
    "    primary_breed = pet.find('div', {'class': head + 'primarybreed'}).get_text(strip=True)\n",
    "    secondary_breed = pet.find('div', {'class': head + 'secondarybreed'}).get_text(strip=True)\n",
    "    age = pet.find('div', {'class': head + 'age'}).get_text(strip=True)\n",
    "    print(name, primary_breed, secondary_breed, age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where each call to `find` is getting the children of a pet object, in particular, the `div`s with `class` attributes which look like `views-field views-field-field-pp-*`. Feel free to replace the above code with the cat or small animal pages provided and see how the output changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often use BeautifulSoup's .find or .find_all methods. However, there are also other useful methods that one can use.  For example, .findNext of .nextSibling. More in the [docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) (especially under tab 'method names'). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I.3: Extract Tables from Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly read a table from html and converge it to a Pandas dataframe with pandas method read_html. Then we can use the regular pandas methods to manipulate or filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Image</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bacon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Often eaten with ketchup or brown sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bacon, egg and cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Breakfast sandwich, usually with fried or scra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagel toast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Pressed, toasted bagel filled with vegetables ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baked bean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Canned baked beans on white or brown bread, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B√°nh m√¨[4]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Filling is typically meat, but can contain a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barbecue[5][6][7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Served on a bun, with chopped, sliced, or shre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barros Jarpa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Ham and cheese, usually mantecoso, which is si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barros Luco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Beef (usually thin-cut steak) and cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bauru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Melted cheese, roast beef, tomato, and pickled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Beef on weck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States(Buffalo, New York)</td>\n",
       "      <td>Roast beef on a Kummelweck roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Beirute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Melted cheese, sliced fresh tomatoes with oreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BLT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Named for its ingredients: bacon, lettuce, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bocadillo de calamares</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Baguette bread filled with fried squid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bologna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States, Canada</td>\n",
       "      <td>Pre-sliced and sometimes fried bologna sausage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Boloney (Bologna) salad sandwich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE Pennsylvania</td>\n",
       "      <td>A mixture of bologna sausage and sweet gherkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bosna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Usually grilled on white bread, containing a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bratwurst Sandwich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>The Bratwurst sandwich is a popular street foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Breakfast roll</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom and Ireland</td>\n",
       "      <td>Convenience dish on a variety of bread rolls, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Typically a scrambled or fried egg, cheese, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>British Rail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Reference to the poor quality of catering on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name Image                            Origin  \\\n",
       "0                              Bacon   NaN                    United Kingdom   \n",
       "1              Bacon, egg and cheese   NaN                     United States   \n",
       "2                        Bagel toast   NaN                            Israel   \n",
       "3                         Baked bean   NaN                     United States   \n",
       "4                         B√°nh m√¨[4]   NaN                           Vietnam   \n",
       "5                  Barbecue[5][6][7]   NaN                     United States   \n",
       "6                       Barros Jarpa   NaN                             Chile   \n",
       "7                        Barros Luco   NaN                             Chile   \n",
       "8                              Bauru   NaN                            Brazil   \n",
       "9                       Beef on weck   NaN  United States(Buffalo, New York)   \n",
       "10                           Beirute   NaN                            Brazil   \n",
       "11                               BLT   NaN                     United States   \n",
       "12            Bocadillo de calamares   NaN                             Spain   \n",
       "13                           Bologna   NaN             United States, Canada   \n",
       "14  Boloney (Bologna) salad sandwich   NaN                   NE Pennsylvania   \n",
       "15                             Bosna   NaN                           Austria   \n",
       "16                Bratwurst Sandwich   NaN                           Germany   \n",
       "17                    Breakfast roll   NaN        United Kingdom and Ireland   \n",
       "18                         Breakfast   NaN                     United States   \n",
       "19                      British Rail   NaN                    United Kingdom   \n",
       "\n",
       "                                          Description  \n",
       "0             Often eaten with ketchup or brown sauce  \n",
       "1   Breakfast sandwich, usually with fried or scra...  \n",
       "2   Pressed, toasted bagel filled with vegetables ...  \n",
       "3   Canned baked beans on white or brown bread, so...  \n",
       "4   Filling is typically meat, but can contain a w...  \n",
       "5   Served on a bun, with chopped, sliced, or shre...  \n",
       "6   Ham and cheese, usually mantecoso, which is si...  \n",
       "7            Beef (usually thin-cut steak) and cheese  \n",
       "8   Melted cheese, roast beef, tomato, and pickled...  \n",
       "9                     Roast beef on a Kummelweck roll  \n",
       "10  Melted cheese, sliced fresh tomatoes with oreg...  \n",
       "11  Named for its ingredients: bacon, lettuce, and...  \n",
       "12             Baguette bread filled with fried squid  \n",
       "13  Pre-sliced and sometimes fried bologna sausage...  \n",
       "14  A mixture of bologna sausage and sweet gherkin...  \n",
       "15  Usually grilled on white bread, containing a b...  \n",
       "16  The Bratwurst sandwich is a popular street foo...  \n",
       "17  Convenience dish on a variety of bread rolls, ...  \n",
       "18  Typically a scrambled or fried egg, cheese, an...  \n",
       "19  Reference to the poor quality of catering on t...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_sandwiches\",header=0)[0]\n",
    "\n",
    "# Write table to CSV\n",
    "#table.to_csv(\"filenamehere.csv\")\n",
    "\n",
    "# Output the top rows of the table\n",
    "table.head((20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use the regular pandas manipulation methods to filter this dataframe or to make changes. For example, we can filter for only animals from the UK as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Image</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bacon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Often eaten with ketchup or brown sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>British Rail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Reference to the poor quality of catering on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cheese and pickle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Slices of cheese (typically Cheddar) and pickl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Chip butty[11][12][13][14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sliced white bread (or a large, flat bread rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Corned beef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Corned beef often served with a condiment such...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name Image          Origin  \\\n",
       "0                        Bacon   NaN  United Kingdom   \n",
       "19                British Rail   NaN  United Kingdom   \n",
       "29           Cheese and pickle   NaN  United Kingdom   \n",
       "37  Chip butty[11][12][13][14]   NaN  United Kingdom   \n",
       "44                 Corned beef   NaN  United Kingdom   \n",
       "\n",
       "                                          Description  \n",
       "0             Often eaten with ketchup or brown sauce  \n",
       "19  Reference to the poor quality of catering on t...  \n",
       "29  Slices of cheese (typically Cheddar) and pickl...  \n",
       "37  Sliced white bread (or a large, flat bread rol...  \n",
       "44  Corned beef often served with a condiment such...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals_from_uk = table[table['Origin'] == 'United Kingdom']\n",
    "animals_from_uk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part  II: Dynamic Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we requested webpages that required no [Javascript](https://en.wikipedia.org/wiki/JavaScript). In other words, there was no input required on the users' end to view the content of the page (e.g. a login). Let's try a more complicated example of webscraping where content is loaded dynamically.\n",
    "\n",
    "[Selenium](https://www.seleniumhq.org/download/)\n",
    "\n",
    "Some advantages of HTML scraping with Selenium it: can handle javascript, get **HTML** back after the Javascript has been rendered, can behave like a person. The disadvantage of using Selenium is that it is generally slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements (one of the below):\n",
    "- Firefox + geckodriver (https://github.com/mozilla/geckodriver/releases)\n",
    "- Chrome + chromedriver (https://sites.google.com/a/chromium.org/chromedriver/)\n",
    "    \n",
    "Note: geckodriver/chromedriver must have execution permissions (chmod +x geckodriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium.webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the driver (change the executable path to geckodriver_mac.exe or geckodriver.exe)\n",
    "# driver = selenium.webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit [xkcd](https://xkcd.com) and click through the comics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the xkcd website\n",
    "driver.get(\"https://xkcd.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the 'random' buttom and go to a random comic\n",
    "# * Yesterday this gave a time-out error, meaning something went wrong in the webserver\n",
    "# If this happens again, rerun last cell and skip this cell \n",
    "random_element = driver.find_element_by_xpath('//*[@id=\"middleContainer\"]/ul[1]/li[3]/a')\n",
    "random_element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the 'previous' button and go to the next comic\n",
    "next_element = driver.find_element_by_css_selector(\"a[rel='prev']\")\n",
    "next_element.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the examples above, there are several ways to identify elements on the page, such as with the xpath or by css selectors. You can find more methods in the [docs](https://onlinetraining.etestinghub.com/webdriver-methods-web-elements/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find an attribute of this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Alpha Centauri'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the title of the comic\n",
    "element_title = driver.find_element_by_id(\"ctitle\")\n",
    "element_title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"And let's be honest, it's more like two and a half stars. Proxima is barely a star and barely bound to the system.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the title of the comic image (not visible on the page in the browser!)\n",
    "element = driver.find_element_by_xpath('//*[@id=\"comic\"]/img')\n",
    "element.get_attribute(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the url changes as you click through the comics. If we would want to download all the comics from this website, we don't necessary need to click through via selenium. Instead, we could simply get (via requests) all these urls with changes integer \"https://xkcd.com/<integer>\". This would be much faster.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visit a webpage which requires a login. Signing in to Facebook ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DO NOT WRITE YOUR PASSWORD IN NOTEBOOKS!!\n",
    "# Write your email below\n",
    "fb_email = \"annakeuchenius@hotmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to Facebook\n",
    "driver = selenium.webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "driver.get(\"https://www.facebook.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now fill out your password, don't hit enter and move on to the next cell in this notebook\n"
     ]
    }
   ],
   "source": [
    "# Send email and password\n",
    "driver.find_element_by_xpath('//*[@id=\"email\"]').send_keys(fb_email)\n",
    "print(\"Now fill out your password, don't hit enter and move on to the next cell in this notebook\")\n",
    "# driver.find_element_by_xpath('//*[@id=\"pass\"]').send_keys(fb_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on login\n",
    "driver.find_element_by_xpath('//*[@id=\"loginbutton\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to CSS Amsterdam Website\n",
    "driver.get(\"https://www.facebook.com/CSSamsterdam/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vind_ik_leuks = driver.find_element_by_xpath(\"//*[contains(text(), 'Vind ik leuk')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always remember to close your browser!\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have now required you fill out your password manually. However, usually when scraping you don't want to do this manually, but instead you want to automate it. Of course you could put your password in your  notebook and fill them out on the website automatically, just like with your email. However, from a security perspective, this is not your best solution. Instead, you can put your passwords in a file, and make your notebook read the password from the file. It is especially important not to put your passwords in your notebooks when you share your scripts directly with others, or submit them to a gitserver (like github)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow users to access large amounts of data, companies may provide an [Application Programming Interface (API)](https://en.wikipedia.org/wiki/Application_programming_interface). Often these request are handled via PUT and POST HTTP requests. For example, to make a request from the Twitter API:\n",
    "\n",
    "```{bash}\n",
    "curl --request GET \n",
    " --url 'https://api.twitter.com/1.1/search/tweets.json?q=nasa&result_type=popular' \n",
    " --header 'authorization: OAuth oauth_consumer_key=\"consumer-key-for-app\", ... , \n",
    " oauth_token=\"access-token-for-authed-user\", oauth_version=\"1.0\"'\n",
    " ```\n",
    "\n",
    "APIs often return data in the format of [Javascript Object Notation (JSON)](https://en.wikipedia.org/wiki/JSON). For example:\n",
    "\n",
    "```{json}\n",
    "{\"status\": 200, \"message\": \"hello world\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit APIs\n",
    "\n",
    "Next, let's try a more typical example of an API. The perks of this approach: \n",
    "- (a) send a request and get back JSON, \n",
    "- (b) chances are that somebody else has created a Python wrapper for you, but keep in mind that \n",
    "- (c) APIs have limits.\n",
    "\n",
    "Let's consider a common API example -- Twitter. To get started:\n",
    "- Get a key: https://apps.twitter.com/\n",
    "- Documentation: https://dev.twitter.com/rest/public\n",
    "- Find a library: https://dev.twitter.com/resources/twitter-libraries (We'll use https://github.com/tweepy/tweepy)\n",
    "\n",
    "Limitations: 100 messages / query, 180 messages every 15 min, & only the last seven days of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find the twitter keys that were created for this demo. Please don't use these keys after this datascraping course any longer. GENEREALLY, NEVER STORE PASSWORD, KEYS OR OTHER SENSITIVE INFORMATION IN NOTEBOOKS. * We will also regenerate these keys after today, so that the ones below are no longer valid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_keys = {}\n",
    "d_keys['CONSUMER_KEY'] = 'iISHnFwAbqlBehAP6RxUIjawG'\n",
    "d_keys['CONSUMER_SECRET'] = 'XJTe1LlhZMSaRHE7SH1paZGwzb2HNbd5GyeDgI9HoLVoeBoBVM'\n",
    "d_keys['ACCESS_KEY'] = '3001441779-A3BEX2aY86j7yOsjwiZ7bRYmFkHnfpsSaPVtaBs'\n",
    "d_keys['ACCESS_SECRET'] = 'qa1ZKpMZPmKqoKJUvD4Gdw3GWhuMRHtIrFvkR7DYoaLHc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________\n",
      "(u'ODISSEI_nl', None, 102)\n",
      "ODISSEI proudly cooperates with the @IC2S2 conference on Computational Social Science in Amsterdam. https://t.co/chyjPIhJ9A\n",
      "__________\n",
      "(u'MNoel75', None, 446)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'nicbaya', None, 879)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'jpgcrowley', None, 474)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'EASSH_', None, 235)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'Akbaritabar', None, 1492)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'dotsbyname', None, 77)\n",
      "RT @UvACORPNET: CORPNET is hosting International Conference on Computational Social Science @IC2S2 next summer. Call for abstracts and tuto‚Ä¶\n",
      "__________\n",
      "(u'grow_andre', None, 495)\n",
      "RT @UvACORPNET: CORPNET is hosting International Conference on Computational Social Science @IC2S2 next summer. Call for abstracts and tuto‚Ä¶\n",
      "__________\n",
      "(u'BasHofstra', None, 664)\n",
      "RT @UvACORPNET: CORPNET is hosting International Conference on Computational Social Science @IC2S2 next summer. Call for abstracts and tuto‚Ä¶\n",
      "__________\n",
      "(u'teamoswald', None, 76)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'ziegelem', None, 275)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'UvACORPNET', None, 523)\n",
      "CORPNET is hosting International Conference on Computational Social Science @IC2S2 next summer. Call for abstracts‚Ä¶ https://t.co/ibxIvKoiUz\n",
      "__________\n",
      "(u'dimitriscc', None, 95)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'Lenafrescamente', None, 271)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'jorcastillosep', None, 101)\n",
      "5th International Conference on Computational Social Science in Amsterdam next year: https://t.co/17XMo9Dy90\n",
      "__________\n",
      "(u'BruceCronin', None, 201)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'RECENS_network', None, 123)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'PeterBaeck', None, 1585)\n",
      "RT @HelenMargetts: So the great computational social science conference @ic2s2 is coming round again - get your proposals in by Feb 5th! Ju‚Ä¶\n",
      "__________\n",
      "(u'chfan1993', None, 26)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'iniguezg', None, 346)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'jminguillona', None, 1054)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'carlcolglazier', None, 435)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'lenikrsova', None, 2491)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'MrMeritology', None, 2424)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'ryanjgallag', None, 1350)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'msantolini', None, 713)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'Shugars', None, 983)\n",
      "@davidlazer IC2S2 conflicts with PolMeth, unfortunately. üò¢#WhyCantIGoToAllTheConferences\n",
      "__________\n",
      "(u'schochastics', None, 208)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'GuyLaban', None, 64)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'JRHelmus', None, 546)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'kayladelahaye', None, 273)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'aymeric_vie', None, 103)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'DzGuilbeault', None, 478)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'TonyLStewart', None, 978)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'JudeHKurniawan', None, 62)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'soramame0518', None, 472)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'jakehofman', None, 5186)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'yearrypanji', None, 325)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'ica_cm', None, 266)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'ladamic', None, 10586)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'stefanjwojcik', None, 322)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'metaAnnelies', None, 1418)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'diliara_valeeva', None, 191)\n",
      "Deadlines for #IC2S2 are very soon. But you need only 1-2 page abstract and, if you are lucky, you are in Amsterdam‚Ä¶ https://t.co/WaNETf5STX\n",
      "__________\n",
      "(u'NapoKo_', None, 525)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'KFrenken', None, 2072)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'dennisfeehan', None, 351)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'leoferres', None, 760)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'leoferres', None, 760)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'BerlinerLufti', None, 699)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'SrebLetina', None, 81)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'openp2pdesign', None, 5996)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'brsepulvado', None, 254)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'desertnaut', None, 989)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'RenseC', None, 434)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'RenseC', None, 434)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'PeterKerkhof', None, 2901)\n",
      "Deze al gezien, @renebekkers en @tyskevdb? https://t.co/ubTaHibSVV\n",
      "__________\n",
      "(u'renebekkers', None, 1367)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'BruceCronin', None, 201)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'rsfrankl', None, 421)\n",
      "RT @HelenMargetts: So the great computational social science conference @ic2s2 is coming round again - get your proposals in by Feb 5th! Ju‚Ä¶\n",
      "__________\n",
      "(u'winsonpeng2011', None, 164)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'net_science', None, 5104)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'colaresi', None, 1517)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'onyilam', None, 251)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'c_deane', None, 2054)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'aaronclauset', None, 6005)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'HelenMargetts', None, 5571)\n",
      "So the great computational social science conference @ic2s2 is coming round again - get your proposals in by Feb 5t‚Ä¶ https://t.co/NF5lNEPs6Q\n",
      "__________\n",
      "(u'DigDemLab', None, 980)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'AlfonsoLangle', None, 189)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'dirk_hovy', None, 4645)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'kaltenburger', None, 363)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'fj_leonm', None, 235)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'dvladek', None, 189)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'guerrero_oa', None, 410)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'msalganik', None, 4168)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'seanwbrooks', None, 827)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'mrfrank5790', None, 325)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'wrahool', None, 670)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'mtaylor_soc', None, 303)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'BasHofstra', None, 664)\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'duncanjwatts', None, 16037)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'davidlazer', None, 8233)\n",
      "Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "(u'damian0604', None, 1274)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'LauraK_Nelson', None, 644)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'silviamajo', None, 1571)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'judith_moeller', None, 595)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'NICOatNU', None, 1075)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'vtraag', None, 1269)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'IlsePit', None, 111)\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,‚Ä¶\n",
      "__________\n",
      "(u'IC2S2', None, 1648)\n",
      "Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals‚Ä¶ https://t.co/V6hOWnWnhX\n",
      "__________\n",
      "(u'drjessehoey', None, 185)\n",
      "RT @RenseC: The call for papers for my favorite computational social science conference @ICS2S2 is now online! https://t.co/vNR9qqGGJn\n",
      "Number of results: 90 (90 new)\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def twitter(d_keys,query, num_results=1000):\n",
    "    # Authtentify\n",
    "    auth = tweepy.OAuthHandler(d_keys[\"CONSUMER_KEY\"], d_keys[\"CONSUMER_SECRET\"])\n",
    "    auth.set_access_token(d_keys[\"ACCESS_KEY\"], d_keys[\"ACCESS_SECRET\"])\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # We want 1000 tweets\n",
    "    result_count = 0\n",
    "    last_id = None\n",
    "    \n",
    "    # Max 180 tweets 15 min\n",
    "    cumulative = 1\n",
    "\n",
    "    #While we don't have them\n",
    "    while (result_count <  num_results):\n",
    "        previous_tweets = result_count\n",
    "        # Ask for more tweets, starting in the 'last_id' (identifier of the tweet)\n",
    "        results = api.search(q = query,\n",
    "                              count = 90, max_id = last_id, result_type=\"recent\")\n",
    "                                # geocode = \"{},{},{}km\".format(latitude, longitude, max_range) #for geocode\n",
    "\n",
    "        # For each tweet extract some info (JSON structure)\n",
    "        for result in results:\n",
    "            result_count += 1\n",
    "            user = result.user.screen_name\n",
    "            text = result.text\n",
    "            followers_count = result.user.followers_count\n",
    "            time_zone = result.user.time_zone\n",
    "            print(\"_\"*10)\n",
    "            print(user,time_zone,followers_count)\n",
    "            print(text)\n",
    "\n",
    "        # Keep the last_id to know where to continue\n",
    "        last_id = int(result.id)-1\n",
    "        new_tweets = result_count - previous_tweets\n",
    "\n",
    "        print (\"Number of results: {} ({} new)\".format(result_count,new_tweets))\n",
    "\n",
    "        # If we don't get new tweets exit\n",
    "        if new_tweets == 0: \n",
    "            break\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        if ((result_count + 90) // 150) > cumulative:\n",
    "            cumulative += 1\n",
    "            time.sleep(15*60)\n",
    "\n",
    "\n",
    "twitter(d_keys,\"ic2s2\", num_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Scraping Issues\n",
    "please see note book css2018-webscraping-advanced"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
