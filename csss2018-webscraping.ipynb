{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datascraping : Web Scraping / APIs\n",
    "Dec 10th, 2018 - Javier Garcia-Bernardo, Anna Keuchenius & Allie Morgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Requirements\n",
    "import requests               # Simple HTTP operations (GET and POST)\n",
    "import selenium               # Loads dynamic (javascript) pages\n",
    "import json                   # Parsing the responses from APIs\n",
    "import re                     # Python library for parsing regular expressions\n",
    "from bs4 import BeautifulSoup # Parsing HTML\n",
    "import pandas as pd           # Read tables\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is datascraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data scraping](https://en.wikipedia.org/wiki/Web_scraping) is a method for extracting data from the web. There are many techniques which can be used for web scraping — ranging from requiring human involvement (“human copy-paste”) to fully automated systems (using computer vision). Somewhere in the middle is HTML parsing, which we will describe here.\n",
    "\n",
    "Web scraping using [HTML parsing](https://en.wikipedia.org/wiki/Web_scraping#HTML_parsing) is often used on webpages which share similar HTML structure. For example, you might want to scrape the ingredients from chocolate chip cookie recipes to identify correlations between ingredients and five-star worthy cookies, or you might want to predict who will win March Madness by looking at game play-by-plays, or you want to know all the local pets up for adoption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Static Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of basics request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://cssamsterdam.github.io/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<!--[if IE 8 ]><html class=\"no-js oldie ie8\" lang=\"en\"> <![endif]-->\\r\\n<!--[if IE 9 ]><html class=\"no-js oldie ie9\" lang=\"en\"> <![endif]-->\\r\\n<!--[if (gte IE 9)|!(IE)]><!--><html class=\"no-js\" lang=\"en\"> <!--<![endif]-->\\r\\n<head>\\r\\n\\r\\n   <!--- basic page needs\\r\\n   ================================================== -->\\r\\n   <meta charset=\"utf-8\">\\r\\n\\t<title>Computational Social Science -- Amsterdam</title>\\r\\n\\t<meta name=\"description\" content=\"\">  \\r\\n\\t<meta name=\"author\" content=\"\">\\r\\n\\r\\n   <!-- mobile specific metas\\r\\n   ================================================== -->\\r\\n\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\">\\r\\n\\r\\n \\t<!-- CSS\\r\\n   ================================================== -->\\r\\n   <link rel=\"stylesheet\" href=\"css/base.css\">  \\r\\n   <link rel=\"stylesheet\" href=\"css/main.css\">\\r\\n   <link rel=\"stylesheet\" href=\"css/vendor.css\">  \\r\\n\\r\\n\\r\\n   <!-- script\\r\\n   ================================================== -->\\r\\n\\t<script src=\"js/moderni'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<head>\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta charset=\"utf-8\" />\n",
      "<link rel=\"shortcut icon\" href=\"https://www.boulderhumane.org/sites/default/files/favicon.ico\" type=\"image/vnd.microsoft.icon\" />\n",
      "<meta name=\"Generator\" content=\"Drupal 7 (http://drupal.org)\" />\n",
      "<meta name=\"viewport\" content=\"width=1000px, initial-scale=1.0, maximum-scale=1.0\" />\n",
      "<title>Dogs Available for Adoption | Humane Society of Boulder Valley</title>\n",
      "<link type=\"text/css\" rel=\"stylesheet\n"
     ]
    }
   ],
   "source": [
    "urls = [\"https://www.boulderhumane.org/animals/adoption/dogs\", \n",
    "         \"https://www.boulderhumane.org/animals/adoption/cats\", \n",
    "         \"https://www.boulderhumane.org/animals/adoption/adopt_other\"]\n",
    "\n",
    "page = requests.get(urls[0])\n",
    "# Extractt \n",
    "html = page.text\n",
    "print(html[:500]) # Print the first 500 characters of the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information: parsing html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you visit a webpage, your web browser renders an HTML document with CSS and Javascript to produce a visually appealing page. (See the HTML above.) [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) is a Python library for parsing HTML. We'll use it to extract all of the names, ages, and breeds of the [dogs](https://www.boulderhumane.org/animals/adoption/dogs), [cats](https://www.boulderhumane.org/animals/adoption/cats), and [small animals](https://www.boulderhumane.org/animals/adoption/adopt_other) currently up for adoption at the Boulder Humane Society."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that the feature of these pages which we are exploiting is their repeated HTML structure. Every animal listed has the following HTML variant:\n",
    "```{html}\n",
    "<div class=\"views-row ... \">\n",
    "  ...\n",
    "  <div class=\"views-field views-field-field-pp-animalname\">\n",
    "    <div class=\"field-content\">\n",
    "      <a href=\"/animals/adoption/\" title=\"Adopt Me!\">Romeo</a>\n",
    "    </div>\n",
    "  </div>\n",
    "  <div class=\"views-field views-field-field-pp-primarybreed\">\n",
    "    <div class=\"field-content\">New Zealand</div>\n",
    "  </div>\n",
    "  <div class=\"views-field views-field-field-pp-secondarybreed\">\n",
    "    <div class=\"field-content\">Rabbit</div>\n",
    "  </div>\n",
    "  <div class=\"views-field views-field-field-pp-age\">\n",
    "    ...\n",
    "    <span class=\"field-content\">0 years 2 months</span>\n",
    "  </div>\n",
    "  <div class=\"views-field views-field-field-pp-gender\">\n",
    "    ...\n",
    "    <span class=\"field-content\">Male</span>\n",
    "  </div>\n",
    "  ...\n",
    "</div>\n",
    "``` \n",
    "So to get at the HTML object for each pet, we can run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pets = soup.find_all('div', {'class': re.compile('.*views-row.*')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, find all of the `div` tags with the `class` attribute which contains the substring `views-row`. \n",
    "\n",
    "remark: notice that we use regex here in the re.compile statement. Regex helps to find patterns in text. More info on regex [here](https://docs.python.org/3/library/re.html). The wildcard .* matches everything (all characters).\n",
    "\n",
    "Next, to grab the name, breeds, and ages of these pets, we’ll grab the children of each pet HTML object. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue Coonhound, Treeing Walker  Age:7 years 5 months\n",
      "Calvin Pointer, German Shorthaired Mix Age:1 year 9 months\n",
      "Mona Greyhound Retriever, Labrador Age:8 years 1 month\n",
      "Momma Hound Mix Age:2 years 0 months\n",
      "Ivy Terrier, Bull  Age:4 years 7 months\n",
      "Karma Terrier, American Pit Bull Mix Age:3 years 0 months\n",
      "Chuco Terrier, American Pit Bull Mix Age:3 years 7 months\n",
      "Harper Terrier, American Pit Bull Mix Age:1 year 1 month\n",
      "Della Retriever, Labrador Mix Age:2 years 0 months\n",
      "Oliver Alaskan Klee Kai  Age:7 years 10 months\n",
      "Holly Australian Cattle Dog Mix Age:0 years 10 months\n",
      "Joey Retriever, Labrador Mix Age:3 years 8 months\n",
      "Eve Miniature Pinscher  Age:0 years 4 months\n",
      "Lola Anatolian Shepherd  Age:0 years 9 months\n",
      "Mary Jane Boxer Mix Age:1 year 6 months\n",
      "Stevie Shih Tzu Maltese Age:0 years 10 months\n",
      "Stella German Shepherd Mix Age:3 years 0 months\n",
      "Elizabeth Australian Cattle Dog Mix Age:0 years 3 months\n",
      "Slade Australian Shepherd Mix Age:0 years 5 months\n",
      "Brandy Retriever, Labrador Mix Age:0 years 6 months\n",
      "Dolly German Shepherd Mix Age:0 years 2 months\n",
      "Lizzy German Shepherd Mix Age:0 years 2 months\n",
      "Tessy German Shepherd Mix Age:0 years 2 months\n",
      "Donny German Shepherd Mix Age:0 years 2 months\n",
      "Duke Australian Cattle Dog Mix Age:0 years 2 months\n",
      "Danny Australian Cattle Dog Mix Age:0 years 2 months\n",
      "Mavis Australian Cattle Dog Mix Age:0 years 2 months\n",
      "Bruno German Shepherd Mix Age:7 years 0 months\n",
      "Bailey Terrier, American Pit Bull Mix Age:0 years 10 months\n",
      "Lucy Australian Cattle Dog Mix Age:0 years 7 months\n",
      "Betty Terrier, American Pit Bull Great Dane Age:0 years 9 months\n",
      "Danny Boy Retriever, Labrador Mix Age:0 years 9 months\n"
     ]
    }
   ],
   "source": [
    "head = \"views-field views-field-field-pp-\"\n",
    "for pet in pets:\n",
    "    name = pet.find('div', {'class': head + 'animalname'}).get_text(strip=True)\n",
    "    primary_breed = pet.find('div', {'class': head + 'primarybreed'}).get_text(strip=True)\n",
    "    secondary_breed = pet.find('div', {'class': head + 'secondarybreed'}).get_text(strip=True)\n",
    "    age = pet.find('div', {'class': head + 'age'}).get_text(strip=True)\n",
    "    print(name, primary_breed, secondary_breed, age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where each call to `find` is getting the children of a pet object, in particular, the `div`s with `class` attributes which look like `views-field views-field-field-pp-*`. Feel free to replace the above code with the cat or small animal pages provided and see how the output changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often use BeautifulSoup's .find or .find_all methods. However, there are also other useful methods that one can use.  For example, .findNext of .nextSibling. More in the [docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) (especially under tab 'method names'). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I.3: Extract Tables from Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly read a table from html and converge it to a Pandas dataframe with pandas method read_html. Then we can use the regular pandas methods to manipulate or filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Image</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bacon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Often eaten with ketchup or brown sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bacon, egg and cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Breakfast sandwich, usually with fried or scra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagel toast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Pressed, toasted bagel filled with vegetables ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baked bean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Canned baked beans on white or brown bread, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bánh mì[4]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Filling is typically meat, but can contain a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barbecue[5][6][7]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Served on a bun, with chopped, sliced, or shre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barros Jarpa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Ham and cheese, usually mantecoso, which is si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barros Luco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Beef (usually thin-cut steak) and cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bauru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Melted cheese, roast beef, tomato, and pickled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Beef on weck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States(Buffalo, New York)</td>\n",
       "      <td>Roast beef on a Kummelweck roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Beirute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Melted cheese, sliced fresh tomatoes with oreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BLT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Named for its ingredients: bacon, lettuce, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bocadillo de calamares</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Baguette bread filled with fried squid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bologna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States, Canada</td>\n",
       "      <td>Pre-sliced and sometimes fried bologna sausage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Boloney (Bologna) salad sandwich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE Pennsylvania</td>\n",
       "      <td>A mixture of bologna sausage and sweet gherkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bosna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Usually grilled on white bread, containing a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bratwurst Sandwich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>The Bratwurst sandwich is a popular street foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Breakfast roll</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom and Ireland</td>\n",
       "      <td>Convenience dish on a variety of bread rolls, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Typically a scrambled or fried egg, cheese, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>British Rail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Reference to the poor quality of catering on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name Image                            Origin  \\\n",
       "0                              Bacon   NaN                    United Kingdom   \n",
       "1              Bacon, egg and cheese   NaN                     United States   \n",
       "2                        Bagel toast   NaN                            Israel   \n",
       "3                         Baked bean   NaN                     United States   \n",
       "4                         Bánh mì[4]   NaN                           Vietnam   \n",
       "5                  Barbecue[5][6][7]   NaN                     United States   \n",
       "6                       Barros Jarpa   NaN                             Chile   \n",
       "7                        Barros Luco   NaN                             Chile   \n",
       "8                              Bauru   NaN                            Brazil   \n",
       "9                       Beef on weck   NaN  United States(Buffalo, New York)   \n",
       "10                           Beirute   NaN                            Brazil   \n",
       "11                               BLT   NaN                     United States   \n",
       "12            Bocadillo de calamares   NaN                             Spain   \n",
       "13                           Bologna   NaN             United States, Canada   \n",
       "14  Boloney (Bologna) salad sandwich   NaN                   NE Pennsylvania   \n",
       "15                             Bosna   NaN                           Austria   \n",
       "16                Bratwurst Sandwich   NaN                           Germany   \n",
       "17                    Breakfast roll   NaN        United Kingdom and Ireland   \n",
       "18                         Breakfast   NaN                     United States   \n",
       "19                      British Rail   NaN                    United Kingdom   \n",
       "\n",
       "                                          Description  \n",
       "0             Often eaten with ketchup or brown sauce  \n",
       "1   Breakfast sandwich, usually with fried or scra...  \n",
       "2   Pressed, toasted bagel filled with vegetables ...  \n",
       "3   Canned baked beans on white or brown bread, so...  \n",
       "4   Filling is typically meat, but can contain a w...  \n",
       "5   Served on a bun, with chopped, sliced, or shre...  \n",
       "6   Ham and cheese, usually mantecoso, which is si...  \n",
       "7            Beef (usually thin-cut steak) and cheese  \n",
       "8   Melted cheese, roast beef, tomato, and pickled...  \n",
       "9                     Roast beef on a Kummelweck roll  \n",
       "10  Melted cheese, sliced fresh tomatoes with oreg...  \n",
       "11  Named for its ingredients: bacon, lettuce, and...  \n",
       "12             Baguette bread filled with fried squid  \n",
       "13  Pre-sliced and sometimes fried bologna sausage...  \n",
       "14  A mixture of bologna sausage and sweet gherkin...  \n",
       "15  Usually grilled on white bread, containing a b...  \n",
       "16  The Bratwurst sandwich is a popular street foo...  \n",
       "17  Convenience dish on a variety of bread rolls, ...  \n",
       "18  Typically a scrambled or fried egg, cheese, an...  \n",
       "19  Reference to the poor quality of catering on t...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_sandwiches\",header=0)[0]\n",
    "\n",
    "# Write table to CSV\n",
    "#table.to_csv(\"filenamehere.csv\")\n",
    "\n",
    "# Output the top rows of the table\n",
    "table.head((20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use the regular pandas manipulation methods to filter this dataframe or to make changes. For example, we can filter for only animals from the UK as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Image</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bacon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Often eaten with ketchup or brown sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>British Rail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Reference to the poor quality of catering on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cheese and pickle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Slices of cheese (typically Cheddar) and pickl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Chip butty[11][12][13][14]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sliced white bread (or a large, flat bread rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Corned beef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Corned beef often served with a condiment such...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name Image          Origin  \\\n",
       "0                        Bacon   NaN  United Kingdom   \n",
       "19                British Rail   NaN  United Kingdom   \n",
       "29           Cheese and pickle   NaN  United Kingdom   \n",
       "37  Chip butty[11][12][13][14]   NaN  United Kingdom   \n",
       "44                 Corned beef   NaN  United Kingdom   \n",
       "\n",
       "                                          Description  \n",
       "0             Often eaten with ketchup or brown sauce  \n",
       "19  Reference to the poor quality of catering on t...  \n",
       "29  Slices of cheese (typically Cheddar) and pickl...  \n",
       "37  Sliced white bread (or a large, flat bread rol...  \n",
       "44  Corned beef often served with a condiment such...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals_from_uk = table[table['Origin'] == 'United Kingdom']\n",
    "animals_from_uk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part  II: Dynamic Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we requested webpages that required no [Javascript](https://en.wikipedia.org/wiki/JavaScript). In other words, there was no input required on the users' end to view the content of the page (e.g. a login). Let's try a more complicated example of webscraping where content is loaded dynamically.\n",
    "\n",
    "[Selenium](https://www.seleniumhq.org/download/)\n",
    "\n",
    "Some advantages of HTML scraping with Selenium it: can handle javascript, get **HTML** back after the Javascript has been rendered, can behave like a person. The disadvantage of using Selenium is that it is generally slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements (one of the below):\n",
    "- Firefox + geckodriver (https://github.com/mozilla/geckodriver/releases)\n",
    "- Chrome + chromedriver (https://sites.google.com/a/chromium.org/chromedriver/)\n",
    "    \n",
    "Note: geckodriver/chromedriver must have execution permissions (chmod +x geckodriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /home/javiergb/Programs/anaconda3/lib/python3.5/site-packages (3.14.0)\r\n",
      "Requirement already satisfied: urllib3 in /home/javiergb/Programs/anaconda3/lib/python3.5/site-packages (from selenium) (1.23)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import selenium.webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open the driver (change the executable path to geckodriver_mac.exe or geckodriver.exe)\n",
    "driver = selenium.webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "# driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit [xkcd](https://xkcd.com) and click through the comics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the xkcd website\n",
    "driver.get(\"https://xkcd.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's find the 'random' buttom and go to a random comic\n",
    "# * Yesterday this gave a time-out error, meaning something went wrong in the webserver\n",
    "# If this happens again, rerun last cell and skip this cell \n",
    "random_element = driver.find_element_by_xpath('//*[@id=\"middleContainer\"]/ul[2]/li[2]/a')\n",
    "random_element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identify the 'previous' button and go to the next comic\n",
    "next_element = driver.find_element_by_css_selector(\"a[rel='prev']\")\n",
    "next_element.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the examples above, there are several ways to identify elements on the page, such as with the xpath or by css selectors. You can find more methods in the [docs](https://onlinetraining.etestinghub.com/webdriver-methods-web-elements/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find an attribute of this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alpha Centauri'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the title of the comic\n",
    "element_title = driver.find_element_by_id(\"ctitle\")\n",
    "element_title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"And let's be honest, it's more like two and a half stars. Proxima is barely a star and barely bound to the system.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the title of the comic image (not visible on the page in the browser!)\n",
    "element = driver.find_element_by_xpath('//*[@id=\"comic\"]/img')\n",
    "element.get_attribute(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the url changes as you click through the comics. If we would want to download all the comics from this website, we don't necessary need to click through via selenium. Instead, we could simply get (via requests) all these urls with changes integer \"https://xkcd.com/<integer>\". This would be much faster.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visit a webpage which requires a login. Signing in to Facebook ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DO NOT WRITE YOUR PASSWORD IN NOTEBOOKS!!\n",
    "# Write your email below\n",
    "fb_email = \"annakeuchenius@hotmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Go to Facebook\n",
    "driver = selenium.webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "driver.get(\"https://www.facebook.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now fill out your password, don't hit enter and move on to the next cell in this notebook\n"
     ]
    }
   ],
   "source": [
    "# Send email and password\n",
    "driver.find_element_by_xpath('//*[@id=\"email\"]').send_keys(fb_email)\n",
    "print(\"Now fill out your password, don't hit enter and move on to the next cell in this notebook\")\n",
    "# driver.find_element_by_xpath('//*[@id=\"pass\"]').send_keys(fb_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Click on login\n",
    "driver.find_element_by_xpath('//*[@id=\"loginbutton\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Go to CSS Amsterdam Website\n",
    "driver.get(\"https://www.facebook.com/CSSamsterdam/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vind_ik_leuks = driver.find_element_by_xpath(\"//*[contains(text(), 'Vind ik leuk')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Always remember to close your browser!\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have now required you fill out your password manually. However, usually when scraping you don't want to do this manually, but instead you want to automate it. Of course you could put your password in your  notebook and fill them out on the website automatically, just like with your email. However, from a security perspective, this is not your best solution. Instead, you can put your passwords in a file, and make your notebook read the password from the file. It is especially important not to put your passwords in your notebooks when you share your scripts directly with others, or submit them to a gitserver (like github)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow users to access large amounts of data, companies may provide an [Application Programming Interface (API)](https://en.wikipedia.org/wiki/Application_programming_interface). Often these request are handled via PUT and POST HTTP requests. For example, to make a request from the Twitter API:\n",
    "\n",
    "```{bash}\n",
    "curl --request GET \n",
    " --url 'https://api.twitter.com/1.1/search/tweets.json?q=nasa&result_type=popular' \n",
    " --header 'authorization: OAuth oauth_consumer_key=\"consumer-key-for-app\", ... , \n",
    " oauth_token=\"access-token-for-authed-user\", oauth_version=\"1.0\"'\n",
    " ```\n",
    "\n",
    "APIs often return data in the format of [Javascript Object Notation (JSON)](https://en.wikipedia.org/wiki/JSON). For example:\n",
    "\n",
    "```{json}\n",
    "{\"status\": 200, \"message\": \"hello world\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit APIs\n",
    "\n",
    "Next, let's try a more typical example of an API. The perks of this approach: \n",
    "- (a) send a request and get back JSON, \n",
    "- (b) chances are that somebody else has created a Python wrapper for you, but keep in mind that \n",
    "- (c) APIs have limits.\n",
    "\n",
    "Let's consider a common API example -- Twitter. To get started:\n",
    "- Get a key: https://apps.twitter.com/\n",
    "- Documentation: https://dev.twitter.com/rest/public\n",
    "- Find a library: https://dev.twitter.com/resources/twitter-libraries (We'll use https://github.com/tweepy/tweepy)\n",
    "\n",
    "Limitations: 100 messages / query, 180 messages every 15 min, & only the last seven days of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find the twitter keys that were created for this demo. Please don't use these keys after this datascraping course any longer. GENEREALLY, NEVER STORE PASSWORD, KEYS OR OTHER SENSITIVE INFORMATION IN NOTEBOOKS. * We will also regenerate these keys after today, so that the ones below are no longer valid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_keys = {}\n",
    "d_keys['CONSUMER_KEY'] = 'iISHnFwAbqlBehAP6RxUIjawG'\n",
    "d_keys['CONSUMER_SECRET'] = 'XJTe1LlhZMSaRHE7SH1paZGwzb2HNbd5GyeDgI9HoLVoeBoBVM'\n",
    "d_keys['ACCESS_KEY'] = '3001441779-A3BEX2aY86j7yOsjwiZ7bRYmFkHnfpsSaPVtaBs'\n",
    "d_keys['ACCESS_SECRET'] = 'qa1ZKpMZPmKqoKJUvD4Gdw3GWhuMRHtIrFvkR7DYoaLHc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________\n",
      "ODISSEI_nl None 102\n",
      "ODISSEI proudly cooperates with the @IC2S2 conference on Computational Social Science in Amsterdam. https://t.co/chyjPIhJ9A\n",
      "__________\n",
      "MNoel75 None 446\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "nicbaya None 879\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "jpgcrowley None 474\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "EASSH_ None 235\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "Akbaritabar None 1493\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "dotsbyname None 77\n",
      "RT @UvACORPNET: CORPNET is hosting International Conference on Computational Social Science @IC2S2 next summer. Call for abstracts and tuto…\n",
      "__________\n",
      "grow_andre None 496\n",
      "RT @UvACORPNET: CORPNET is hosting International Conference on Computational Social Science @IC2S2 next summer. Call for abstracts and tuto…\n",
      "__________\n",
      "BasHofstra None 664\n",
      "RT @UvACORPNET: CORPNET is hosting International Conference on Computational Social Science @IC2S2 next summer. Call for abstracts and tuto…\n",
      "__________\n",
      "teamoswald None 76\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "ziegelem None 275\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "UvACORPNET None 523\n",
      "CORPNET is hosting International Conference on Computational Social Science @IC2S2 next summer. Call for abstracts… https://t.co/ibxIvKoiUz\n",
      "__________\n",
      "dimitriscc None 95\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "Lenafrescamente None 272\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "jorcastillosep None 101\n",
      "5th International Conference on Computational Social Science in Amsterdam next year: https://t.co/17XMo9Dy90\n",
      "__________\n",
      "BruceCronin None 201\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "RECENS_network None 123\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "PeterBaeck None 1585\n",
      "RT @HelenMargetts: So the great computational social science conference @ic2s2 is coming round again - get your proposals in by Feb 5th! Ju…\n",
      "__________\n",
      "chfan1993 None 26\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "iniguezg None 346\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "jminguillona None 1055\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "carlcolglazier None 434\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "lenikrsova None 2492\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "MrMeritology None 2424\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "ryanjgallag None 1349\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "msantolini None 715\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "Shugars None 982\n",
      "@davidlazer IC2S2 conflicts with PolMeth, unfortunately. 😢#WhyCantIGoToAllTheConferences\n",
      "__________\n",
      "schochastics None 207\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "GuyLaban None 65\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "JRHelmus None 546\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "kayladelahaye None 272\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "aymeric_vie None 103\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "DzGuilbeault None 478\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "TonyLStewart None 978\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "JudeHKurniawan None 62\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "soramame0518 None 472\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "jakehofman None 5187\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "yearrypanji None 325\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "ica_cm None 266\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "ladamic None 10585\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "stefanjwojcik None 322\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "metaAnnelies None 1418\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "diliara_valeeva None 191\n",
      "Deadlines for #IC2S2 are very soon. But you need only 1-2 page abstract and, if you are lucky, you are in Amsterdam… https://t.co/WaNETf5STX\n",
      "__________\n",
      "NapoKo_ None 525\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "KFrenken None 2072\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "dennisfeehan None 352\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "leoferres None 760\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "leoferres None 760\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "BerlinerLufti None 699\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "SrebLetina None 81\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "openp2pdesign None 5996\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "brsepulvado None 254\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "desertnaut None 989\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "RenseC None 434\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "RenseC None 434\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "PeterKerkhof None 2901\n",
      "Deze al gezien, @renebekkers en @tyskevdb? https://t.co/ubTaHibSVV\n",
      "__________\n",
      "renebekkers None 1366\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "BruceCronin None 201\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "rsfrankl None 420\n",
      "RT @HelenMargetts: So the great computational social science conference @ic2s2 is coming round again - get your proposals in by Feb 5th! Ju…\n",
      "__________\n",
      "winsonpeng2011 None 164\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "net_science None 5104\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "colaresi None 1516\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "onyilam None 252\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "c_deane None 2052\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "aaronclauset None 6003\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "HelenMargetts None 5571\n",
      "So the great computational social science conference @ic2s2 is coming round again - get your proposals in by Feb 5t… https://t.co/NF5lNEPs6Q\n",
      "__________\n",
      "DigDemLab None 980\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "AlfonsoLangle None 189\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "dirk_hovy None 4645\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "kaltenburger None 363\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "fj_leonm None 235\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "dvladek None 189\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "guerrero_oa None 410\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "msalganik None 4171\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "seanwbrooks None 827\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "mrfrank5790 None 325\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "wrahool None 670\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "mtaylor_soc None 303\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "BasHofstra None 664\n",
      "RT @davidlazer: Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "duncanjwatts None 16039\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "davidlazer None 8231\n",
      "Calling all computational social scientists!! Get your proposals in by Feb 5. https://t.co/XYSXMHqdUT\n",
      "__________\n",
      "damian0604 None 1275\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "LauraK_Nelson None 644\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "silviamajo None 1571\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "judith_moeller None 595\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "NICOatNU None 1075\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "vtraag None 1269\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "IlsePit None 112\n",
      "RT @IC2S2: Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals is January 4,…\n",
      "__________\n",
      "IC2S2 None 1647\n",
      "Call for papers for #IC2S2 in Amsterdam is now online: https://t.co/Z6nJB7kA8n The deadline for tutorial proposals… https://t.co/V6hOWnWnhX\n",
      "__________\n",
      "drjessehoey None 185\n",
      "RT @RenseC: The call for papers for my favorite computational social science conference @ICS2S2 is now online! https://t.co/vNR9qqGGJn\n",
      "Number of results: 90 (90 new)\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def twitter(d_keys,query, num_results=1000):\n",
    "    # Authtentify\n",
    "    auth = tweepy.OAuthHandler(d_keys[\"CONSUMER_KEY\"], d_keys[\"CONSUMER_SECRET\"])\n",
    "    auth.set_access_token(d_keys[\"ACCESS_KEY\"], d_keys[\"ACCESS_SECRET\"])\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # We want 1000 tweets\n",
    "    result_count = 0\n",
    "    last_id = None\n",
    "    \n",
    "    # Max 180 tweets 15 min\n",
    "    cumulative = 1\n",
    "\n",
    "    #While we don't have them\n",
    "    while (result_count <  num_results):\n",
    "        previous_tweets = result_count\n",
    "        # Ask for more tweets, starting in the 'last_id' (identifier of the tweet)\n",
    "        results = api.search(q = query,\n",
    "                              count = 90, max_id = last_id, result_type=\"recent\")\n",
    "                                # geocode = \"{},{},{}km\".format(latitude, longitude, max_range) #for geocode\n",
    "\n",
    "        # For each tweet extract some info (JSON structure)\n",
    "        for result in results:\n",
    "            result_count += 1\n",
    "            user = result.user.screen_name\n",
    "            text = result.text\n",
    "            followers_count = result.user.followers_count\n",
    "            time_zone = result.user.time_zone\n",
    "            print(\"_\"*10)\n",
    "            print(user,time_zone,followers_count)\n",
    "            print(text)\n",
    "\n",
    "        # Keep the last_id to know where to continue\n",
    "        last_id = int(result.id)-1\n",
    "        new_tweets = result_count - previous_tweets\n",
    "\n",
    "        print (\"Number of results: {} ({} new)\".format(result_count,new_tweets))\n",
    "\n",
    "        # If we don't get new tweets exit\n",
    "        if new_tweets == 0: \n",
    "            break\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        if ((result_count + 90) // 150) > cumulative:\n",
    "            cumulative += 1\n",
    "            time.sleep(15*60)\n",
    "\n",
    "\n",
    "twitter(d_keys,\"ic2s2\", num_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Scraping Issues\n",
    "please see note book css2018-webscraping-advanced"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
